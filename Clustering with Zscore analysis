#https://www.dataquest.io/blog/machine-learning-python/

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn import preprocessing

# Read in the data.
df = pd.read_csv("/Users/jney/Desktop/top50.csv")
# Print the names of the columns in games.
print(df.columns)

features = ['Prior', 'Post', 'Maker_vol', 'Taker_vol']

# Remove any rows with missing values and remove bad columns aka 'Unnamed: 0'
df = df.dropna(axis=0)
df = df.drop('Unnamed: 0', axis=1)

#create a new df with std for each column
print df.agg(['min', 'max', 'std'])

# Initialize the model with 2 parameters -- number of clusters and random state.
kmeans_model = KMeans(n_clusters=5, random_state=123, init='k-means++', n_init=10)
# Fit the model using the good columns.
kmeans_model.fit(df[features])
df['label'] = kmeans_model.predict(df[features])

#print the number of values in each cluster
print df['label'].value_counts()

#print the trader info for cluster1 - so after the '==' input the cluster number aka 0 that you want to see the first 5 rows for
#head() shows first 5 instances, .tail()
print df[ df['label'] == 0 ].head()

#create a new df where the cell values are replaced with scaled z-score values
scaler = preprocessing.StandardScaler().fit(df[features])
scale_good_columns = pd.DataFrame(scaler.transform(df[features]), columns=features)

scale_good_columns.head()
unscaled = pd.DataFrame(scaler.inverse_transform(scale_good_columns), columns=features)
print df[features].head()
print unscaled.head()


#show the centers of the 5 clusters
print kmeans_model.cluster_centers_
#add labels to the dataframe as a new column called "cluster"
df["cluster"]= labels5


